{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/vasilistimoudas/spaceship-titanic?scriptVersionId=145121499\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Introduction","metadata":{}},{"cell_type":"markdown","source":"This is a Kaggle competition, and it's available at https://www.kaggle.com/competitions/spaceship-titanic\n\nI live in the year 2912 and I have to solve a cosmic mystery. The Spaceship Titanic was an interstellar passenger liner and launched a month ago with almost 13,000 passengers on board. The vessel set out on it's maiden voyage transporting emigrants from our solar system to three newly habitable exoplanets orbiting nearby stars. The Spaceship Titanic collided with a spacetime anomaly hidden within a dust cloud and almost half of the passengers were transported to an alternate dimension. The goal of this competition is to predict which passengers were transported from the spaceship's damaged computer system.\n\nIn this competition, I have a binary classification problem, and I will use several machine learning algorithms to predict which passengers were transported. In the end, I will evaluate each algorithm and select the one with the highest prediction accuracy.","metadata":{}},{"cell_type":"markdown","source":"****<span style=\"font-size:16px;\"> Vasileios Panagiotis Timoudas****\n<br>Github: https://github.com/vasilis-timoudas\n<br>Linkedin: https://www.linkedin.com/in/vasileios-timoudas ","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries and Load Data","metadata":{}},{"cell_type":"code","source":"# Import libraries\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style='darkgrid')","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:43.004907Z","iopub.execute_input":"2023-10-03T16:07:43.005488Z","iopub.status.idle":"2023-10-03T16:07:44.003722Z","shell.execute_reply.started":"2023-10-03T16:07:43.005356Z","shell.execute_reply":"2023-10-03T16:07:44.00239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import train and test data\ntrain_data_full = pd.read_csv('../input/spaceship-titanic/train.csv')\ntest_data_full = pd.read_csv('../input/spaceship-titanic/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:44.005736Z","iopub.execute_input":"2023-10-03T16:07:44.006178Z","iopub.status.idle":"2023-10-03T16:07:44.066021Z","shell.execute_reply.started":"2023-10-03T16:07:44.006147Z","shell.execute_reply":"2023-10-03T16:07:44.064848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make copy to avoid changing original data \ntrain_data = train_data_full.copy()\ntest_data = test_data_full.copy()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:44.067338Z","iopub.execute_input":"2023-10-03T16:07:44.067679Z","iopub.status.idle":"2023-10-03T16:07:44.074048Z","shell.execute_reply.started":"2023-10-03T16:07:44.067651Z","shell.execute_reply":"2023-10-03T16:07:44.072871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data General Overview","metadata":{}},{"cell_type":"code","source":"# Print the shape of the train and test data\nprint('Train set shape:', train_data.shape)\nprint('Test set shape:', test_data.shape)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:44.077104Z","iopub.execute_input":"2023-10-03T16:07:44.077581Z","iopub.status.idle":"2023-10-03T16:07:44.089019Z","shell.execute_reply.started":"2023-10-03T16:07:44.077503Z","shell.execute_reply":"2023-10-03T16:07:44.087393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the head of the train data\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:44.090804Z","iopub.execute_input":"2023-10-03T16:07:44.09109Z","iopub.status.idle":"2023-10-03T16:07:44.114825Z","shell.execute_reply.started":"2023-10-03T16:07:44.091067Z","shell.execute_reply":"2023-10-03T16:07:44.11393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print basic information of the train data\ntrain_data.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:44.116806Z","iopub.execute_input":"2023-10-03T16:07:44.117118Z","iopub.status.idle":"2023-10-03T16:07:44.133611Z","shell.execute_reply.started":"2023-10-03T16:07:44.117094Z","shell.execute_reply":"2023-10-03T16:07:44.132519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the summary statistics for the numerical columns in the train data\ntrain_data.describe().T","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:44.134656Z","iopub.execute_input":"2023-10-03T16:07:44.135606Z","iopub.status.idle":"2023-10-03T16:07:44.166178Z","shell.execute_reply.started":"2023-10-03T16:07:44.135576Z","shell.execute_reply":"2023-10-03T16:07:44.164845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the the number of the unique values in the train data\ntrain_data.nunique()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:44.167728Z","iopub.execute_input":"2023-10-03T16:07:44.168468Z","iopub.status.idle":"2023-10-03T16:07:44.184822Z","shell.execute_reply.started":"2023-10-03T16:07:44.168412Z","shell.execute_reply":"2023-10-03T16:07:44.183653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the the number of the objects unique values in the train data\ntrain_data.select_dtypes(include='object').nunique()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:44.18594Z","iopub.execute_input":"2023-10-03T16:07:44.187079Z","iopub.status.idle":"2023-10-03T16:07:44.202585Z","shell.execute_reply.started":"2023-10-03T16:07:44.187048Z","shell.execute_reply":"2023-10-03T16:07:44.201676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to find columns with missing values\ndef find_missing_values(df):\n    # Columns with missing values\n    na_cols = df.columns[df.isna().any()].tolist()\n\n    # Missing values summary\n    mv_summary = pd.DataFrame(df[na_cols].isna().sum(), columns=['number_missing'])\n    mv_summary['percentage_missing'] = np.round(100 * mv_summary['number_missing'] / len(df), 2)\n    \n    # Data types of columns\n    mv_summary['column_type'] = df[na_cols].dtypes\n    \n    # Sort by column type\n    mv_summary = mv_summary.sort_values(by=['column_type'])\n    \n    return mv_summary","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:44.206419Z","iopub.execute_input":"2023-10-03T16:07:44.206786Z","iopub.status.idle":"2023-10-03T16:07:44.213415Z","shell.execute_reply.started":"2023-10-03T16:07:44.206758Z","shell.execute_reply":"2023-10-03T16:07:44.212101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"find_missing_values(train_data)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:44.215102Z","iopub.execute_input":"2023-10-03T16:07:44.21607Z","iopub.status.idle":"2023-10-03T16:07:44.250744Z","shell.execute_reply.started":"2023-10-03T16:07:44.216027Z","shell.execute_reply":"2023-10-03T16:07:44.249525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"find_missing_values(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:44.252096Z","iopub.execute_input":"2023-10-03T16:07:44.252538Z","iopub.status.idle":"2023-10-03T16:07:44.274163Z","shell.execute_reply.started":"2023-10-03T16:07:44.252496Z","shell.execute_reply":"2023-10-03T16:07:44.273398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the number of duplicates in training and test data\nprint(f'Duplicates in train set: {train_data.duplicated().sum()}, ({np.round(100 * train_data.duplicated().sum() / len(train_data), 1)}%)')\nprint(f'Duplicates in test set: {test_data.duplicated().sum()}, ({np.round(100 * test_data.duplicated().sum() / len(test_data), 1)}%)')","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:44.275318Z","iopub.execute_input":"2023-10-03T16:07:44.276438Z","iopub.status.idle":"2023-10-03T16:07:44.316111Z","shell.execute_reply.started":"2023-10-03T16:07:44.276403Z","shell.execute_reply":"2023-10-03T16:07:44.314982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the histogram of the train data\ntrain_data.hist(figsize=(15, 8))","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:44.317473Z","iopub.execute_input":"2023-10-03T16:07:44.317762Z","iopub.status.idle":"2023-10-03T16:07:46.133678Z","shell.execute_reply.started":"2023-10-03T16:07:44.317738Z","shell.execute_reply":"2023-10-03T16:07:46.132564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the correlation map of the train data\nsns.heatmap(train_data.corr(numeric_only=True), annot=True, cmap='YlGnBu', linewidths=0.5, fmt='.2f')","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:46.135256Z","iopub.execute_input":"2023-10-03T16:07:46.135598Z","iopub.status.idle":"2023-10-03T16:07:46.681959Z","shell.execute_reply.started":"2023-10-03T16:07:46.13557Z","shell.execute_reply":"2023-10-03T16:07:46.680806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"# Create a figure\nplt.figure(figsize=(5, 5))\n\n# Plot pie chart\ntrain_data['Transported'].value_counts().plot.pie(\n    startangle=0,\n    explode=[0.02, 0.02],\n    autopct='%1.1f%%',\n).set_title(\"Transported\", fontweight='bold')\n\nplt.show()   ","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:46.683444Z","iopub.execute_input":"2023-10-03T16:07:46.683792Z","iopub.status.idle":"2023-10-03T16:07:46.792431Z","shell.execute_reply.started":"2023-10-03T16:07:46.683764Z","shell.execute_reply":"2023-10-03T16:07:46.791705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The features that I will plot\nexpense_features = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n\n# Create a figure\nfig = plt.figure(figsize=(10, 20))\n\n# For each feature I will make 2 subplots\nfor i, exp_feature in enumerate(expense_features):\n    # Left subplot\n    # Create a subplot\n    ax = fig.add_subplot(5, 2, 2*i+1)\n    # Plot histogram and set title\n    sns.histplot(data=train_data, x=exp_feature, axes=ax, bins=30, kde=False, hue='Transported').set_title(exp_feature, fontweight='bold')\n    # Set x and y margins to 0\n    ax.margins(x=0)\n    ax.margins(y=0)\n\n    # Right subplot\n    # Create a subplot\n    ax = fig.add_subplot(5, 2, 2*i+2)\n    # Plot histogram and set title\n    sns.histplot(data=train_data, x=exp_feature, axes=ax, bins=30, kde=True, hue='Transported').set_title(exp_feature, fontweight='bold')\n    # Set y-axis limit\n    plt.ylim([0, 100])\n    # Set x and y margins to 0\n    ax.margins(x=0)\n    ax.margins(y=0)\n\nfig.tight_layout()\nplt.show()   ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-10-03T16:07:46.793695Z","iopub.execute_input":"2023-10-03T16:07:46.794782Z","iopub.status.idle":"2023-10-03T16:07:52.142284Z","shell.execute_reply.started":"2023-10-03T16:07:46.794723Z","shell.execute_reply":"2023-10-03T16:07:52.141531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a figure\nplt.figure(figsize=(10, 4))\n\n# Plot histogram\nsns.histplot(data=train_data, x='Age', hue='Transported', binwidth=1, kde=True)\n\n# Set title\nplt.title('Age Distribution', fontweight='bold')\n\n# Set x-axis label\nplt.xlabel('Age (years)')\n\n# Set x-axis limit\nplt.xlim([0, 80])\n\n# Set x-axis margin\nplt.margins(x=0)\n\nplt.tight_layout()\nplt.show()  ","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:52.14352Z","iopub.execute_input":"2023-10-03T16:07:52.14434Z","iopub.status.idle":"2023-10-03T16:07:53.234102Z","shell.execute_reply.started":"2023-10-03T16:07:52.14431Z","shell.execute_reply":"2023-10-03T16:07:53.232625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Categorical features\ncategorical_features = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP']\n\n# Create a figure\nfig = plt.figure(figsize=(10, 16))\n\n# For each feature I will make a subplot\nfor i, cat_feature in enumerate(categorical_features):\n    # Create subplot\n    ax = fig.add_subplot(4, 1, i+1)\n    # Plot countplot and set title\n    sns.countplot(data=train_data, x=cat_feature, axes=ax, hue='Transported').set_title(cat_feature, fontweight='bold')\n    \nfig.tight_layout() \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:53.236048Z","iopub.execute_input":"2023-10-03T16:07:53.237188Z","iopub.status.idle":"2023-10-03T16:07:54.382349Z","shell.execute_reply.started":"2023-10-03T16:07:53.237136Z","shell.execute_reply":"2023-10-03T16:07:54.381505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Split the column PassengerId into two seperate columns gggg and pp\ntrain_data[['gggg', 'pp']] = train_data['PassengerId'].str.split('_', expand=True)\ntest_data[['gggg', 'pp']] = test_data['PassengerId'].str.split('_', expand=True)\n\n# Converts the values of the columns gggg and pp to float\ntrain_data['gggg'] = train_data['gggg'].astype(float)\ntest_data['gggg'] = test_data['gggg'].astype(float)\ntrain_data['pp'] = train_data['pp'].astype(float)\ntest_data['pp'] = test_data['pp'].astype(float)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:54.383781Z","iopub.execute_input":"2023-10-03T16:07:54.384375Z","iopub.status.idle":"2023-10-03T16:07:54.586975Z","shell.execute_reply.started":"2023-10-03T16:07:54.384345Z","shell.execute_reply":"2023-10-03T16:07:54.586081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the column Cabin into three seperate columns deck, num and side\ntrain_data[['deck', 'num', 'side']] = train_data['Cabin'].str.split('/', expand=True)\ntest_data[['deck', 'num', 'side']] = test_data['Cabin'].str.split('/', expand=True)\n\n# Converts the values of the column num to float\ntrain_data['num'] = train_data['num'].astype(float)\ntest_data['num'] = test_data['num'].astype(float)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:54.588319Z","iopub.execute_input":"2023-10-03T16:07:54.588911Z","iopub.status.idle":"2023-10-03T16:07:54.622546Z","shell.execute_reply.started":"2023-10-03T16:07:54.588878Z","shell.execute_reply":"2023-10-03T16:07:54.621246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sum the values of columns and add them to column Expenditure\ntrain_data['Expenditure'] = train_data[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)\ntest_data['Expenditure'] = test_data[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)\n\n# Converts the values of the column Expenditure to float\ntrain_data['Expenditure'] = train_data['Expenditure'].astype(float)\ntest_data['Expenditure'] = test_data['Expenditure'].astype(float)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:54.623903Z","iopub.execute_input":"2023-10-03T16:07:54.624277Z","iopub.status.idle":"2023-10-03T16:07:54.641656Z","shell.execute_reply.started":"2023-10-03T16:07:54.624245Z","shell.execute_reply":"2023-10-03T16:07:54.640339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Select numerical and categorical cols\nnumerical_cols = [cname for cname in train_data.columns if train_data[cname].dtype in ['int64', 'float64']]\ncategorical_cols = [cname for cname in train_data.columns if train_data[cname].nunique() < 10 and  train_data[cname].dtype == 'object']\n\n# Keep the selected columns only\nmy_cols = numerical_cols + categorical_cols\ntrain_data = train_data[my_cols].join(train_data.Transported)\ntest_data = test_data[my_cols]","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:54.642939Z","iopub.execute_input":"2023-10-03T16:07:54.643221Z","iopub.status.idle":"2023-10-03T16:07:54.665937Z","shell.execute_reply.started":"2023-10-03T16:07:54.643198Z","shell.execute_reply":"2023-10-03T16:07:54.664627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I decided to don't use the feature Expenditure\nnumerical_cols = [item for item in numerical_cols if item != 'Expenditure']\ntrain_data = train_data.drop('Expenditure', axis=1)\ntest_data = test_data.drop('Expenditure', axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:54.666949Z","iopub.execute_input":"2023-10-03T16:07:54.667884Z","iopub.status.idle":"2023-10-03T16:07:54.676327Z","shell.execute_reply.started":"2023-10-03T16:07:54.667847Z","shell.execute_reply":"2023-10-03T16:07:54.675062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\n# Preprocessing for numerical data\nnumerical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler()) \n])\n    \n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore')) \n])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:54.677889Z","iopub.execute_input":"2023-10-03T16:07:54.678511Z","iopub.status.idle":"2023-10-03T16:07:54.806948Z","shell.execute_reply.started":"2023-10-03T16:07:54.678465Z","shell.execute_reply":"2023-10-03T16:07:54.805799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Separate target from predictors\nX = train_data.drop('Transported', axis=1)\ny = train_data.Transported.astype(int)\n\n# Train-validation split\nfrom sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:54.808214Z","iopub.execute_input":"2023-10-03T16:07:54.808546Z","iopub.status.idle":"2023-10-03T16:07:54.82286Z","shell.execute_reply.started":"2023-10-03T16:07:54.808518Z","shell.execute_reply":"2023-10-03T16:07:54.821079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Selection","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\n# The classifiers that I will use\nclassifiers = {\n    'K-Nearest Neighbors': KNeighborsClassifier(),\n    'Logistic Regression': LogisticRegression(solver='liblinear'),\n    'Decision Tree': DecisionTreeClassifier(),\n    'Random Forest': RandomForestClassifier(),\n    'AdaBoost': AdaBoostClassifier(),\n    'Gradient Boosting': GradientBoostingClassifier(),\n    'SVM': SVC(),\n    'Gaussian Naive Bayes': GaussianNB(),\n    'XGBoost': XGBClassifier(),\n    'LightGBM': LGBMClassifier(),\n    'CatBoost': CatBoostClassifier(iterations=100, verbose=0) \n}","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:54.824509Z","iopub.execute_input":"2023-10-03T16:07:54.825107Z","iopub.status.idle":"2023-10-03T16:07:55.701059Z","shell.execute_reply.started":"2023-10-03T16:07:54.825072Z","shell.execute_reply":"2023-10-03T16:07:55.699819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\n\n# Function that finds and returns the accuracy of each classifier\ndef find_classifiers_accuracy(classifiers=classifiers, \n                              preprocessor=preprocessor, \n                              X_train=X_train, \n                              X_valid=X_valid, \n                              y_train=y_train, \n                              y_valid=y_valid, \n                              X=X, \n                              y=y, \n                              is_cross_val=False):\n    \n    accuracy_name = 'Accuracy' if is_cross_val == False else 'Mean Accuracy'\n    results = {'Classifier': [], accuracy_name: []}\n\n    # For each classifier find the accuracy\n    for name, clf in classifiers.items():\n        # Bundle preprocessing and modeling code in a pipeline\n        my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('classifier', clf)\n                             ])\n        \n        if is_cross_val == False:\n            # Preprocessing of training data and fit the classifier \n            my_pipeline.fit(X_train, y_train)\n\n            # Preprocessing of validation data and get predictions\n            y_pred = my_pipeline.predict(X_valid)\n\n            # Calculate accuracy\n            accuracy = accuracy_score(y_pred, y_valid)\n            \n            # Save results\n            results['Classifier'].append(name)\n            results[accuracy_name].append(accuracy)\n        else:\n            # 5-fold cross validation\n            stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n            scores = cross_val_score(my_pipeline, X, y, cv=stratified_kfold) \n            \n            # Calculate mean accuracy\n            mean_accuracy = scores.mean()\n            \n            # Save results\n            results['Classifier'].append(name)\n            results[accuracy_name].append(mean_accuracy)\n    \n    # Create a DataFrame from the results dictionary\n    results_df = pd.DataFrame(results)\n    \n    # Sort DataFrame by accuracy_name\n    results_df = results_df.sort_values(by=accuracy_name, ascending=False)\n    \n    # Reset DataFrame index \n    results_df.reset_index(drop=True, inplace=True)\n        \n    return results_df","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:55.705338Z","iopub.execute_input":"2023-10-03T16:07:55.705733Z","iopub.status.idle":"2023-10-03T16:07:55.717871Z","shell.execute_reply.started":"2023-10-03T16:07:55.705703Z","shell.execute_reply":"2023-10-03T16:07:55.716722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tts_classifiers_accuracy_df = find_classifiers_accuracy(is_cross_val=False)\ntts_classifiers_accuracy_df","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:07:55.719861Z","iopub.execute_input":"2023-10-03T16:07:55.720307Z","iopub.status.idle":"2023-10-03T16:08:04.693713Z","shell.execute_reply.started":"2023-10-03T16:07:55.720185Z","shell.execute_reply":"2023-10-03T16:08:04.692771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_classifiers_accuracy_df = find_classifiers_accuracy(is_cross_val=True)\ncv_classifiers_accuracy_df","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:08:04.694785Z","iopub.execute_input":"2023-10-03T16:08:04.695852Z","iopub.status.idle":"2023-10-03T16:08:51.277511Z","shell.execute_reply.started":"2023-10-03T16:08:04.695809Z","shell.execute_reply":"2023-10-03T16:08:51.276566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tts_best_classifier_name = tts_classifiers_accuracy_df['Classifier'].iloc[0]\ntts_best_classifier_accuracy = tts_classifiers_accuracy_df['Accuracy'].iloc[0]\n\ncv_best_classifier_name = cv_classifiers_accuracy_df['Classifier'].iloc[0]\ncv_best_classifier_accuracy = cv_classifiers_accuracy_df['Mean Accuracy'].iloc[0]\n\n\nif tts_best_classifier_accuracy > cv_best_classifier_accuracy:\n    best_classifier = classifiers[tts_best_classifier_name]\nelse:\n    best_classifier = classifiers[cv_best_classifier_name]","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:08:51.278707Z","iopub.execute_input":"2023-10-03T16:08:51.279216Z","iopub.status.idle":"2023-10-03T16:08:51.287647Z","shell.execute_reply.started":"2023-10-03T16:08:51.27919Z","shell.execute_reply":"2023-10-03T16:08:51.286616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"# Get the best pipeline\nbest_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('classifier', best_classifier)\n                             ])\n\n# Get the predictions of the test data \ny_pred = best_pipeline.predict(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:08:51.289145Z","iopub.execute_input":"2023-10-03T16:08:51.289423Z","iopub.status.idle":"2023-10-03T16:08:51.363813Z","shell.execute_reply.started":"2023-10-03T16:08:51.2894Z","shell.execute_reply":"2023-10-03T16:08:51.362774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"# Read sample submission file\nsubmission = pd.read_csv('../input/spaceship-titanic/sample_submission.csv')\n\n# Add predictions\nsubmission['Transported'] = y_pred\n\n# Replace 0 to False and 1 to True\nsubmission = submission.replace({0:False, 1:True})\n\n# Output to submission file\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T16:08:51.365228Z","iopub.execute_input":"2023-10-03T16:08:51.365841Z","iopub.status.idle":"2023-10-03T16:08:51.388101Z","shell.execute_reply.started":"2023-10-03T16:08:51.36581Z","shell.execute_reply":"2023-10-03T16:08:51.386985Z"},"trusted":true},"execution_count":null,"outputs":[]}]}